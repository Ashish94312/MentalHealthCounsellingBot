{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.7848101265822782,
  "eval_steps": 200,
  "global_step": 1100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02531645569620253,
      "grad_norm": 0.29251745343208313,
      "learning_rate": 9.924050632911392e-06,
      "loss": 2.487,
      "step": 10
    },
    {
      "epoch": 0.05063291139240506,
      "grad_norm": 0.3156469464302063,
      "learning_rate": 9.839662447257383e-06,
      "loss": 2.4948,
      "step": 20
    },
    {
      "epoch": 0.0759493670886076,
      "grad_norm": 0.2528151869773865,
      "learning_rate": 9.755274261603376e-06,
      "loss": 2.5045,
      "step": 30
    },
    {
      "epoch": 0.10126582278481013,
      "grad_norm": 0.27488911151885986,
      "learning_rate": 9.670886075949368e-06,
      "loss": 2.4894,
      "step": 40
    },
    {
      "epoch": 0.12658227848101267,
      "grad_norm": 0.24796231091022491,
      "learning_rate": 9.58649789029536e-06,
      "loss": 2.4556,
      "step": 50
    },
    {
      "epoch": 0.1518987341772152,
      "grad_norm": 0.2764233350753784,
      "learning_rate": 9.502109704641352e-06,
      "loss": 2.4613,
      "step": 60
    },
    {
      "epoch": 0.17721518987341772,
      "grad_norm": 0.32733961939811707,
      "learning_rate": 9.417721518987343e-06,
      "loss": 2.4328,
      "step": 70
    },
    {
      "epoch": 0.20253164556962025,
      "grad_norm": 0.2918342053890228,
      "learning_rate": 9.333333333333334e-06,
      "loss": 2.4201,
      "step": 80
    },
    {
      "epoch": 0.22784810126582278,
      "grad_norm": 0.3088684678077698,
      "learning_rate": 9.248945147679326e-06,
      "loss": 2.3972,
      "step": 90
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.33630314469337463,
      "learning_rate": 9.164556962025317e-06,
      "loss": 2.4413,
      "step": 100
    },
    {
      "epoch": 0.27848101265822783,
      "grad_norm": 0.35035112500190735,
      "learning_rate": 9.080168776371308e-06,
      "loss": 2.3799,
      "step": 110
    },
    {
      "epoch": 0.3037974683544304,
      "grad_norm": 0.44494518637657166,
      "learning_rate": 8.995780590717301e-06,
      "loss": 2.4087,
      "step": 120
    },
    {
      "epoch": 0.3291139240506329,
      "grad_norm": 0.3378296494483948,
      "learning_rate": 8.911392405063292e-06,
      "loss": 2.3548,
      "step": 130
    },
    {
      "epoch": 0.35443037974683544,
      "grad_norm": 0.3760454058647156,
      "learning_rate": 8.827004219409283e-06,
      "loss": 2.3445,
      "step": 140
    },
    {
      "epoch": 0.379746835443038,
      "grad_norm": 0.34709325432777405,
      "learning_rate": 8.742616033755275e-06,
      "loss": 2.4149,
      "step": 150
    },
    {
      "epoch": 0.4050632911392405,
      "grad_norm": 0.2729794383049011,
      "learning_rate": 8.658227848101266e-06,
      "loss": 2.4234,
      "step": 160
    },
    {
      "epoch": 0.43037974683544306,
      "grad_norm": 0.33907508850097656,
      "learning_rate": 8.573839662447259e-06,
      "loss": 2.3353,
      "step": 170
    },
    {
      "epoch": 0.45569620253164556,
      "grad_norm": 0.30129513144493103,
      "learning_rate": 8.48945147679325e-06,
      "loss": 2.3826,
      "step": 180
    },
    {
      "epoch": 0.4810126582278481,
      "grad_norm": 0.3057139217853546,
      "learning_rate": 8.405063291139241e-06,
      "loss": 2.3204,
      "step": 190
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.3082621693611145,
      "learning_rate": 8.320675105485233e-06,
      "loss": 2.31,
      "step": 200
    },
    {
      "epoch": 0.5063291139240507,
      "eval_loss": 2.351719617843628,
      "eval_runtime": 156.816,
      "eval_samples_per_second": 2.245,
      "eval_steps_per_second": 0.281,
      "step": 200
    },
    {
      "epoch": 0.5316455696202531,
      "grad_norm": 0.30450305342674255,
      "learning_rate": 8.236286919831224e-06,
      "loss": 2.3115,
      "step": 210
    },
    {
      "epoch": 0.5569620253164557,
      "grad_norm": 0.27740147709846497,
      "learning_rate": 8.151898734177217e-06,
      "loss": 2.3241,
      "step": 220
    },
    {
      "epoch": 0.5822784810126582,
      "grad_norm": 0.30950257182121277,
      "learning_rate": 8.067510548523208e-06,
      "loss": 2.3254,
      "step": 230
    },
    {
      "epoch": 0.6075949367088608,
      "grad_norm": 0.3147537410259247,
      "learning_rate": 7.9831223628692e-06,
      "loss": 2.353,
      "step": 240
    },
    {
      "epoch": 0.6329113924050633,
      "grad_norm": 0.32483184337615967,
      "learning_rate": 7.89873417721519e-06,
      "loss": 2.3074,
      "step": 250
    },
    {
      "epoch": 0.6582278481012658,
      "grad_norm": 0.35516124963760376,
      "learning_rate": 7.814345991561182e-06,
      "loss": 2.3156,
      "step": 260
    },
    {
      "epoch": 0.6835443037974683,
      "grad_norm": 0.29820290207862854,
      "learning_rate": 7.729957805907173e-06,
      "loss": 2.2911,
      "step": 270
    },
    {
      "epoch": 0.7088607594936709,
      "grad_norm": 0.3909682333469391,
      "learning_rate": 7.645569620253164e-06,
      "loss": 2.3202,
      "step": 280
    },
    {
      "epoch": 0.7341772151898734,
      "grad_norm": 0.3325847387313843,
      "learning_rate": 7.561181434599156e-06,
      "loss": 2.2789,
      "step": 290
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.3499728739261627,
      "learning_rate": 7.4767932489451475e-06,
      "loss": 2.2905,
      "step": 300
    },
    {
      "epoch": 0.7848101265822784,
      "grad_norm": 0.3805815577507019,
      "learning_rate": 7.3924050632911405e-06,
      "loss": 2.316,
      "step": 310
    },
    {
      "epoch": 0.810126582278481,
      "grad_norm": 0.3172130286693573,
      "learning_rate": 7.308016877637132e-06,
      "loss": 2.3182,
      "step": 320
    },
    {
      "epoch": 0.8354430379746836,
      "grad_norm": 0.32131221890449524,
      "learning_rate": 7.223628691983123e-06,
      "loss": 2.3241,
      "step": 330
    },
    {
      "epoch": 0.8607594936708861,
      "grad_norm": 0.3429976999759674,
      "learning_rate": 7.139240506329115e-06,
      "loss": 2.266,
      "step": 340
    },
    {
      "epoch": 0.8860759493670886,
      "grad_norm": 0.34270259737968445,
      "learning_rate": 7.054852320675106e-06,
      "loss": 2.2433,
      "step": 350
    },
    {
      "epoch": 0.9113924050632911,
      "grad_norm": 0.3635775148868561,
      "learning_rate": 6.9704641350210975e-06,
      "loss": 2.2949,
      "step": 360
    },
    {
      "epoch": 0.9367088607594937,
      "grad_norm": 0.4212198555469513,
      "learning_rate": 6.88607594936709e-06,
      "loss": 2.2488,
      "step": 370
    },
    {
      "epoch": 0.9620253164556962,
      "grad_norm": 0.4126180112361908,
      "learning_rate": 6.801687763713081e-06,
      "loss": 2.2899,
      "step": 380
    },
    {
      "epoch": 0.9873417721518988,
      "grad_norm": 0.4349376857280731,
      "learning_rate": 6.717299578059072e-06,
      "loss": 2.2553,
      "step": 390
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.37330853939056396,
      "learning_rate": 6.632911392405063e-06,
      "loss": 2.2509,
      "step": 400
    },
    {
      "epoch": 1.0126582278481013,
      "eval_loss": 2.2825136184692383,
      "eval_runtime": 151.7472,
      "eval_samples_per_second": 2.32,
      "eval_steps_per_second": 0.29,
      "step": 400
    },
    {
      "epoch": 1.0379746835443038,
      "grad_norm": 0.5210237503051758,
      "learning_rate": 6.548523206751055e-06,
      "loss": 2.2913,
      "step": 410
    },
    {
      "epoch": 1.0632911392405062,
      "grad_norm": 0.39247235655784607,
      "learning_rate": 6.464135021097047e-06,
      "loss": 2.301,
      "step": 420
    },
    {
      "epoch": 1.0886075949367089,
      "grad_norm": 0.3787218928337097,
      "learning_rate": 6.379746835443038e-06,
      "loss": 2.2675,
      "step": 430
    },
    {
      "epoch": 1.1139240506329113,
      "grad_norm": 0.4350624084472656,
      "learning_rate": 6.29535864978903e-06,
      "loss": 2.2797,
      "step": 440
    },
    {
      "epoch": 1.139240506329114,
      "grad_norm": 0.41988691687583923,
      "learning_rate": 6.210970464135022e-06,
      "loss": 2.2745,
      "step": 450
    },
    {
      "epoch": 1.1645569620253164,
      "grad_norm": 0.4494699239730835,
      "learning_rate": 6.126582278481013e-06,
      "loss": 2.245,
      "step": 460
    },
    {
      "epoch": 1.189873417721519,
      "grad_norm": 0.42515817284584045,
      "learning_rate": 6.042194092827005e-06,
      "loss": 2.1792,
      "step": 470
    },
    {
      "epoch": 1.2151898734177216,
      "grad_norm": 0.42668676376342773,
      "learning_rate": 5.957805907172997e-06,
      "loss": 2.2407,
      "step": 480
    },
    {
      "epoch": 1.240506329113924,
      "grad_norm": 0.4157205820083618,
      "learning_rate": 5.873417721518988e-06,
      "loss": 2.2802,
      "step": 490
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.5097034573554993,
      "learning_rate": 5.789029535864979e-06,
      "loss": 2.302,
      "step": 500
    },
    {
      "epoch": 1.2911392405063291,
      "grad_norm": 0.36128994822502136,
      "learning_rate": 5.704641350210971e-06,
      "loss": 2.2378,
      "step": 510
    },
    {
      "epoch": 1.3164556962025316,
      "grad_norm": 0.4547579288482666,
      "learning_rate": 5.6202531645569624e-06,
      "loss": 2.2286,
      "step": 520
    },
    {
      "epoch": 1.3417721518987342,
      "grad_norm": 0.375310480594635,
      "learning_rate": 5.535864978902954e-06,
      "loss": 2.3355,
      "step": 530
    },
    {
      "epoch": 1.3670886075949367,
      "grad_norm": 0.4657343327999115,
      "learning_rate": 5.451476793248946e-06,
      "loss": 2.2407,
      "step": 540
    },
    {
      "epoch": 1.3924050632911391,
      "grad_norm": 0.4512481093406677,
      "learning_rate": 5.367088607594937e-06,
      "loss": 2.2373,
      "step": 550
    },
    {
      "epoch": 1.4177215189873418,
      "grad_norm": 0.5136494040489197,
      "learning_rate": 5.282700421940928e-06,
      "loss": 2.238,
      "step": 560
    },
    {
      "epoch": 1.4430379746835442,
      "grad_norm": 0.47789159417152405,
      "learning_rate": 5.1983122362869195e-06,
      "loss": 2.2754,
      "step": 570
    },
    {
      "epoch": 1.4683544303797469,
      "grad_norm": 0.4550054967403412,
      "learning_rate": 5.1139240506329116e-06,
      "loss": 2.27,
      "step": 580
    },
    {
      "epoch": 1.4936708860759493,
      "grad_norm": 0.4704887866973877,
      "learning_rate": 5.029535864978904e-06,
      "loss": 2.2664,
      "step": 590
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 0.37265750765800476,
      "learning_rate": 4.945147679324895e-06,
      "loss": 2.2737,
      "step": 600
    },
    {
      "epoch": 1.518987341772152,
      "eval_loss": 2.268437147140503,
      "eval_runtime": 154.6502,
      "eval_samples_per_second": 2.276,
      "eval_steps_per_second": 0.285,
      "step": 600
    },
    {
      "epoch": 1.5443037974683544,
      "grad_norm": 0.4452876150608063,
      "learning_rate": 4.860759493670886e-06,
      "loss": 2.2532,
      "step": 610
    },
    {
      "epoch": 1.5696202531645569,
      "grad_norm": 0.35826146602630615,
      "learning_rate": 4.776371308016877e-06,
      "loss": 2.2741,
      "step": 620
    },
    {
      "epoch": 1.5949367088607596,
      "grad_norm": 0.39110201597213745,
      "learning_rate": 4.6919831223628695e-06,
      "loss": 2.2485,
      "step": 630
    },
    {
      "epoch": 1.620253164556962,
      "grad_norm": 0.4157818853855133,
      "learning_rate": 4.6075949367088615e-06,
      "loss": 2.2646,
      "step": 640
    },
    {
      "epoch": 1.6455696202531644,
      "grad_norm": 0.5079073905944824,
      "learning_rate": 4.523206751054853e-06,
      "loss": 2.2531,
      "step": 650
    },
    {
      "epoch": 1.6708860759493671,
      "grad_norm": 0.4910392761230469,
      "learning_rate": 4.438818565400844e-06,
      "loss": 2.2206,
      "step": 660
    },
    {
      "epoch": 1.6962025316455698,
      "grad_norm": 0.4668668508529663,
      "learning_rate": 4.354430379746836e-06,
      "loss": 2.2311,
      "step": 670
    },
    {
      "epoch": 1.721518987341772,
      "grad_norm": 0.39596936106681824,
      "learning_rate": 4.270042194092827e-06,
      "loss": 2.2849,
      "step": 680
    },
    {
      "epoch": 1.7468354430379747,
      "grad_norm": 0.3974838852882385,
      "learning_rate": 4.185654008438819e-06,
      "loss": 2.2461,
      "step": 690
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.4234800636768341,
      "learning_rate": 4.101265822784811e-06,
      "loss": 2.2445,
      "step": 700
    },
    {
      "epoch": 1.7974683544303798,
      "grad_norm": 0.4042624831199646,
      "learning_rate": 4.016877637130802e-06,
      "loss": 2.2242,
      "step": 710
    },
    {
      "epoch": 1.8227848101265822,
      "grad_norm": 0.46693068742752075,
      "learning_rate": 3.932489451476794e-06,
      "loss": 2.183,
      "step": 720
    },
    {
      "epoch": 1.8481012658227849,
      "grad_norm": 0.36039888858795166,
      "learning_rate": 3.848101265822785e-06,
      "loss": 2.2599,
      "step": 730
    },
    {
      "epoch": 1.8734177215189873,
      "grad_norm": 0.4193795621395111,
      "learning_rate": 3.7637130801687765e-06,
      "loss": 2.2713,
      "step": 740
    },
    {
      "epoch": 1.8987341772151898,
      "grad_norm": 0.4444396495819092,
      "learning_rate": 3.679324894514768e-06,
      "loss": 2.2414,
      "step": 750
    },
    {
      "epoch": 1.9240506329113924,
      "grad_norm": 0.432243674993515,
      "learning_rate": 3.5949367088607594e-06,
      "loss": 2.2122,
      "step": 760
    },
    {
      "epoch": 1.9493670886075949,
      "grad_norm": 0.5898625254631042,
      "learning_rate": 3.5105485232067515e-06,
      "loss": 2.259,
      "step": 770
    },
    {
      "epoch": 1.9746835443037973,
      "grad_norm": 0.4435868561267853,
      "learning_rate": 3.426160337552743e-06,
      "loss": 2.3039,
      "step": 780
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4922563433647156,
      "learning_rate": 3.3417721518987344e-06,
      "loss": 2.2978,
      "step": 790
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.5666389465332031,
      "learning_rate": 3.257383966244726e-06,
      "loss": 2.3014,
      "step": 800
    },
    {
      "epoch": 2.0253164556962027,
      "eval_loss": 2.263253927230835,
      "eval_runtime": 166.3051,
      "eval_samples_per_second": 2.117,
      "eval_steps_per_second": 0.265,
      "step": 800
    },
    {
      "epoch": 2.050632911392405,
      "grad_norm": 0.5606486797332764,
      "learning_rate": 3.1729957805907173e-06,
      "loss": 2.245,
      "step": 810
    },
    {
      "epoch": 2.0759493670886076,
      "grad_norm": 0.4307788610458374,
      "learning_rate": 3.088607594936709e-06,
      "loss": 2.2353,
      "step": 820
    },
    {
      "epoch": 2.1012658227848102,
      "grad_norm": 0.4744179844856262,
      "learning_rate": 3.0042194092827006e-06,
      "loss": 2.3025,
      "step": 830
    },
    {
      "epoch": 2.1265822784810124,
      "grad_norm": 0.49025672674179077,
      "learning_rate": 2.9198312236286923e-06,
      "loss": 2.2529,
      "step": 840
    },
    {
      "epoch": 2.151898734177215,
      "grad_norm": 0.5184260010719299,
      "learning_rate": 2.835443037974684e-06,
      "loss": 2.2176,
      "step": 850
    },
    {
      "epoch": 2.1772151898734178,
      "grad_norm": 0.5247286558151245,
      "learning_rate": 2.751054852320675e-06,
      "loss": 2.2552,
      "step": 860
    },
    {
      "epoch": 2.2025316455696204,
      "grad_norm": 0.5033789277076721,
      "learning_rate": 2.666666666666667e-06,
      "loss": 2.2943,
      "step": 870
    },
    {
      "epoch": 2.2278481012658227,
      "grad_norm": 0.41526636481285095,
      "learning_rate": 2.5822784810126585e-06,
      "loss": 2.2136,
      "step": 880
    },
    {
      "epoch": 2.2531645569620253,
      "grad_norm": 0.4812440574169159,
      "learning_rate": 2.49789029535865e-06,
      "loss": 2.2039,
      "step": 890
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 0.4696910083293915,
      "learning_rate": 2.4135021097046414e-06,
      "loss": 2.2158,
      "step": 900
    },
    {
      "epoch": 2.3037974683544302,
      "grad_norm": 0.5241122841835022,
      "learning_rate": 2.329113924050633e-06,
      "loss": 2.2327,
      "step": 910
    },
    {
      "epoch": 2.329113924050633,
      "grad_norm": 0.511706531047821,
      "learning_rate": 2.2447257383966247e-06,
      "loss": 2.2759,
      "step": 920
    },
    {
      "epoch": 2.3544303797468356,
      "grad_norm": 0.46425366401672363,
      "learning_rate": 2.1603375527426164e-06,
      "loss": 2.2171,
      "step": 930
    },
    {
      "epoch": 2.379746835443038,
      "grad_norm": 0.4596302807331085,
      "learning_rate": 2.0759493670886076e-06,
      "loss": 2.2494,
      "step": 940
    },
    {
      "epoch": 2.4050632911392404,
      "grad_norm": 0.45472535490989685,
      "learning_rate": 1.9915611814345993e-06,
      "loss": 2.297,
      "step": 950
    },
    {
      "epoch": 2.430379746835443,
      "grad_norm": 0.5726544857025146,
      "learning_rate": 1.907172995780591e-06,
      "loss": 2.2033,
      "step": 960
    },
    {
      "epoch": 2.4556962025316453,
      "grad_norm": 0.4943113923072815,
      "learning_rate": 1.8227848101265824e-06,
      "loss": 2.2675,
      "step": 970
    },
    {
      "epoch": 2.481012658227848,
      "grad_norm": 0.4531296491622925,
      "learning_rate": 1.7383966244725739e-06,
      "loss": 2.2402,
      "step": 980
    },
    {
      "epoch": 2.5063291139240507,
      "grad_norm": 0.46567586064338684,
      "learning_rate": 1.6540084388185657e-06,
      "loss": 2.2619,
      "step": 990
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.41866397857666016,
      "learning_rate": 1.5696202531645572e-06,
      "loss": 2.2759,
      "step": 1000
    },
    {
      "epoch": 2.5316455696202533,
      "eval_loss": 2.2606425285339355,
      "eval_runtime": 210.4601,
      "eval_samples_per_second": 1.673,
      "eval_steps_per_second": 0.209,
      "step": 1000
    },
    {
      "epoch": 2.5569620253164556,
      "grad_norm": 0.6264985799789429,
      "learning_rate": 1.4852320675105486e-06,
      "loss": 2.2695,
      "step": 1010
    },
    {
      "epoch": 2.5822784810126582,
      "grad_norm": 0.5228796005249023,
      "learning_rate": 1.40084388185654e-06,
      "loss": 2.2602,
      "step": 1020
    },
    {
      "epoch": 2.607594936708861,
      "grad_norm": 0.5381996631622314,
      "learning_rate": 1.3164556962025317e-06,
      "loss": 2.262,
      "step": 1030
    },
    {
      "epoch": 2.632911392405063,
      "grad_norm": 0.5697776675224304,
      "learning_rate": 1.2320675105485234e-06,
      "loss": 2.2472,
      "step": 1040
    },
    {
      "epoch": 2.6582278481012658,
      "grad_norm": 0.5139585733413696,
      "learning_rate": 1.1476793248945149e-06,
      "loss": 2.2844,
      "step": 1050
    },
    {
      "epoch": 2.6835443037974684,
      "grad_norm": 0.4335915446281433,
      "learning_rate": 1.0632911392405063e-06,
      "loss": 2.1991,
      "step": 1060
    },
    {
      "epoch": 2.708860759493671,
      "grad_norm": 0.47478705644607544,
      "learning_rate": 9.78902953586498e-07,
      "loss": 2.2249,
      "step": 1070
    },
    {
      "epoch": 2.7341772151898733,
      "grad_norm": 0.5515657663345337,
      "learning_rate": 8.945147679324894e-07,
      "loss": 2.2732,
      "step": 1080
    },
    {
      "epoch": 2.759493670886076,
      "grad_norm": 0.45756959915161133,
      "learning_rate": 8.101265822784811e-07,
      "loss": 2.2593,
      "step": 1090
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 0.4281110167503357,
      "learning_rate": 7.257383966244725e-07,
      "loss": 2.2835,
      "step": 1100
    }
  ],
  "logging_steps": 10,
  "max_steps": 1185,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.80883965722624e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

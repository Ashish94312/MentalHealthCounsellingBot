{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from enum import Enum\n",
    "from datasets import load_dataset\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data classes created successfully!\n"
     ]
    }
   ],
   "source": [
    "class RoleType(Enum):\n",
    "   \n",
    "    USER = 'user'\n",
    "    SYSTEM = 'system'\n",
    "    ASSISTANT = 'assistant'\n",
    "\n",
    "\n",
    "class Role:\n",
    "\n",
    "    \n",
    "    def __init__(self, role_type: RoleType, content: str):\n",
    "        self.role = role_type.value\n",
    "        self.content = content\n",
    "        self.value = {'role': self.role, 'content': self.content}\n",
    "\n",
    "\n",
    "class Message:\n",
    "\n",
    "    \n",
    "    def __init__(self, user_content: str, system_content: str, assistant_content: str):\n",
    "        self.user_role = Role(role_type=RoleType.USER, content=user_content)\n",
    "        self.system_role = Role(role_type=RoleType.SYSTEM, content=system_content)\n",
    "        self.assistant_role = Role(role_type=RoleType.ASSISTANT, content=assistant_content)\n",
    "        \n",
    "        self.message = {\n",
    "            \"messages\": [\n",
    "                self.system_role.value,\n",
    "                self.user_role.value,\n",
    "                self.assistant_role.value\n",
    "            ]\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Data classes created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully! Total samples: 3512\n",
      "Sample keys: dict_keys(['Context', 'Response'])\n"
     ]
    }
   ],
   "source": [
    "# Load the mental health counseling dataset\n",
    "dataset = load_dataset(\n",
    "    \"Amod/mental_health_counseling_conversations\",\n",
    "    data_files=\"combined_dataset.json\",\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded successfully! Total samples: {len(dataset)}\")\n",
    "print(f\"Sample keys: {dataset[0].keys()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample message format:\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user's emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It's important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"I am really worried about one of my friends because I think he has major depression. He disagrees with me on that. He is shut off when it comes to talking to people and telling them how he really feels. He told me he feels empty inside and the only emotions he feels are anger and sadness. I suggested to him to get help and talk to his mom about it but he refuses.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"First of all, I can tell that you really care about your friend and I think it's great that you are reaching out with your concern. It's hard to determine whether your friend would meet the criteria for an official diagnosis of depression without working with him, however, whether he does or not, therapy may be beneficial for him in working through these difficult feelings and relational challenges. Unfortunately, you can't make your friend get help. He will ultimately need to make that decision for himself, however, you can talk to him about your concerns and your hopes that he will reach out for help.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for mental health counseling\n",
    "SYSTEM_PROMPT = \"\"\"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user's emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It's important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\"\"\n",
    "\n",
    "# Create a sample Message object to test the format\n",
    "sample_context = dataset[152][\"Context\"]\n",
    "sample_response = dataset[152][\"Response\"]\n",
    "sample_message = Message(\n",
    "    user_content=sample_context,\n",
    "    system_content=SYSTEM_PROMPT,\n",
    "    assistant_content=sample_response\n",
    ")\n",
    "\n",
    "print(\"Sample message format:\")\n",
    "print(json.dumps(sample_message.message, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 100 training samples\n"
     ]
    }
   ],
   "source": [
    "def save_to_jsonl(data, file_path):\n",
    "    \"\"\"Save data to JSONL format for OpenAI fine-tuning.\"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        for row in data:\n",
    "            # Extract the dict representation\n",
    "            if hasattr(row, \"message\"):\n",
    "                row = row.message\n",
    "            line = json.dumps(row)\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "# Sample a subset of the dataset for training\n",
    "sampled_dataset = random.choices(dataset, k=100)\n",
    "train_dataset = []\n",
    "\n",
    "for row in sampled_dataset:\n",
    "    message_obj = Message(\n",
    "        user_content=row['Context'],\n",
    "        system_content=SYSTEM_PROMPT,\n",
    "        assistant_content=row['Response']\n",
    "    )\n",
    "    train_dataset.append(message_obj)\n",
    "\n",
    "print(f\"Created {len(train_dataset)} training samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n",
      "Training data: ./data/train.jsonl (95 samples)\n",
      "Validation data: ./data/validation.jsonl (5 samples)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and validation sets\n",
    "train_data = train_dataset[:-5]  # First 95 samples for training\n",
    "validation_data = train_dataset[-5:]  # Last 5 samples for validation\n",
    "\n",
    "# Save data in JSONL format\n",
    "training_data_path = './data/train.jsonl'\n",
    "validation_data_path = './data/validation.jsonl'\n",
    "\n",
    "save_to_jsonl(train_data, training_data_path)\n",
    "save_to_jsonl(validation_data, validation_data_path)\n",
    "\n",
    "print(\"Data saved successfully!\")\n",
    "print(f\"Training data: {training_data_path} ({len(train_data)} samples)\")\n",
    "print(f\"Validation data: {validation_data_path} ({len(validation_data)} samples)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fine-Tune the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\" OpenAI client initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading files to OpenAI...\n",
      "Training file ID: file-U81b4UCMvjeziYB8L2MDLS\n",
      "Validation file ID: file-PsXxmeBNswnAWiwHgCUDnM\n",
      "Training file status: processed\n",
      "Validation file status: processed\n"
     ]
    }
   ],
   "source": [
    "# Upload training and validation files to OpenAI\n",
    "print(\"üì§ Uploading files to OpenAI...\")\n",
    "\n",
    "with open(training_data_path, \"rb\") as training_file:\n",
    "    training_response = client.files.create(file=training_file, purpose=\"fine-tune\")\n",
    "    training_file_id = training_response.id\n",
    "\n",
    "with open(validation_data_path, \"rb\") as validation_file:\n",
    "    validation_response = client.files.create(file=validation_file, purpose=\"fine-tune\")\n",
    "    validation_file_id = validation_response.id\n",
    "\n",
    "print(f\"Training file ID: {training_file_id}\")\n",
    "print(f\"Validation file ID: {validation_file_id}\")\n",
    "print(f\"Training file status: {training_response.status}\")\n",
    "print(f\"Validation file status: {validation_response.status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating fine-tuning job...\n",
      "‚úÖ Fine-tuning job created successfully!\n",
      "üìã Job ID: ftjob-DqQecglYdHm9vSdbNyzvl1a9\n",
      "üìä Job Status: validating_files\n",
      "ü§ñ Model: gpt-4o-2024-08-06\n"
     ]
    }
   ],
   "source": [
    "# Create fine-tuning job\n",
    "print(\"üöÄ Creating fine-tuning job...\")\n",
    "\n",
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    "    suffix=\"mental-health-counselor\",\n",
    "    validation_file=validation_file_id\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "print(f\"‚úÖ Fine-tuning job created successfully!\")\n",
    "print(f\"üìã Job ID: {job_id}\")\n",
    "print(f\"üìä Job Status: {response.status}\")\n",
    "print(f\"ü§ñ Model: {response.model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Monitoring fine-tuning job progress...\n",
      "üìä Job Status: validating_files\n",
      "ü§ñ Model: gpt-4o-2024-08-06\n",
      "‚è≥ Fine-tuning in progress. Status: validating_files\n",
      "Please wait for completion...\n"
     ]
    }
   ],
   "source": [
    "# Monitor fine-tuning job progress\n",
    "print(\"üîç Monitoring fine-tuning job progress...\")\n",
    "\n",
    "try:\n",
    "    job_status = client.fine_tuning.jobs.retrieve(job_id)\n",
    "    print(f\"üìä Job Status: {job_status.status}\")\n",
    "    print(f\"ü§ñ Model: {job_status.model}\")\n",
    "    \n",
    "    if job_status.status == \"succeeded\":\n",
    "        print(\"‚úÖ Fine-tuning completed successfully!\")\n",
    "        print(f\"üéØ Fine-tuned Model ID: {job_status.fine_tuned_model}\")\n",
    "    elif job_status.status == \"failed\":\n",
    "        print(\"‚ùå Fine-tuning failed!\")\n",
    "        print(f\"Error: {job_status.error}\")\n",
    "    elif job_status.status in [\"validating_files\", \"queued\", \"running\"]:\n",
    "        print(f\"‚è≥ Fine-tuning in progress. Status: {job_status.status}\")\n",
    "        print(\"Please wait for completion...\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Unknown status: {job_status.status}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error retrieving job status: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test message prepared:\n",
      "User: Every winter I find myself getting sad because of the weather. How can I fight this?\n"
     ]
    }
   ],
   "source": [
    "# Prepare test messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": \"Every winter I find myself getting sad because of the weather. How can I fight this?\"}\n",
    "]\n",
    "\n",
    "print(\"Test message prepared:\")\n",
    "print(f\"User: {messages[1]['content']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Testing base model (gpt-4o-2024-08-06)...\n",
      "Base model response:\n",
      "I'm really sorry to hear that the winter months can be tough for you. It's not uncommon for people to feel this way, as the shorter and darker days can affect our moods. Here are a few suggestions that might help:\n",
      "\n",
      "1. **Light Therapy:** Consider using a light therapy box. It mimics natural sunlight and can help improve your mood and regulate your sleep patterns.\n",
      "\n",
      "2. **Stay Active:** Even though it might be tempting to stay indoors, regular physical activity can boost your mood and energy levels.\n",
      "\n",
      "3. **Social Connections:** Try to stay connected with family and friends. Socializing, even if it's just a phone call or video chat, can be uplifting.\n",
      "\n",
      "4. **Professional Help:** If these feelings become overwhelming, consider speaking with a therapist. They can provide support and strategies tailored to your situation.\n",
      "\n",
      "5. **Plan Pleasant Activities:** Schedule things to look forward to, like hobbies or outings, which can make the winter months more enjoyable.\n",
      "\n",
      "6. **Mindfulness and Relaxation:** Practices such as meditation or yoga can help manage stress and improve your mood.\n",
      "\n",
      "Remember, it's okay to seek support if you're feeling down. Everyone's experience is different, and finding what works for you is important. Take gentle care of yourself, and don't hesitate to reach out to a professional if needed.\n"
     ]
    }
   ],
   "source": [
    "# Test with base model (GPT-3.5-turbo)\n",
    "print(\"ü§ñ Testing base model (gpt-4o-2024-08-06)...\")\n",
    "\n",
    "try:\n",
    "    completion_base = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=messages\n",
    "    )\n",
    "    print(\"Base model response:\")\n",
    "    print(completion_base.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error testing base model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Fine-tuned model not available yet. Please wait for training to complete.\n"
     ]
    }
   ],
   "source": [
    "# Test with fine-tuned model (if available)\n",
    "if 'job_status' in locals() and job_status.status == \"succeeded\" and job_status.fine_tuned_model:\n",
    "    print(\"\\nü§ñ Testing fine-tuned model...\")\n",
    "    \n",
    "    try:\n",
    "        completion_ft = client.chat.completions.create(\n",
    "            model=job_status.fine_tuned_model,\n",
    "            messages=messages\n",
    "        )\n",
    "        print(\"Fine-tuned model response:\")\n",
    "        print(completion_ft.choices[0].message.content)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚úÖ Fine-tuning is working! Compare the responses above.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error testing fine-tuned model: {e}\")\n",
    "else:\n",
    "    print(\"\\n Fine-tuned model not available yet. Please wait for training to complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
